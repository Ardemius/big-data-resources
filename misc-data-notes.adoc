= Misc notes about Data
Thomas SCHWENDER <icon:github[] https://github.com/Ardemius/[GitHub] / icon:twitter[role="aqua"] https://twitter.com/thomasschwender[@thomasschwender]>
// Handling GitHub admonition blocks icons
ifndef::env-github[:icons: font]
ifdef::env-github[]
:status:
:outfilesuffix: .adoc
:caution-caption: :fire:
:important-caption: :exclamation:
:note-caption: :paperclip:
:tip-caption: :bulb:
:warning-caption: :warning:
endif::[]
:imagesdir: ./images
:resourcesdir: ./resources
:source-highlighter: highlightjs
:highlightjs-languages: asciidoc
// We must enable experimental attribute to display Keyboard, button, and menu macros
:experimental:
// Next 2 ones are to handle line breaks in some particular elements (list, footnotes, etc.)
:lb: pass:[<br> +]
:sb: pass:[<br>]
// check https://github.com/Ardemius/personal-wiki/wiki/AsciiDoctor-tips for tips on table of content in GitHub
:toc: macro
:toclevels: 4
// To number the sections of the table of contents
//:sectnums:
// Add an anchor with hyperlink before the section title
:sectanchors:
// To turn off figure caption labels and numbers
:figure-caption!:
// Same for examples
//:example-caption!:
// To turn off ALL captions
// :caption:

toc::[]

Un bloc-notes pour persister toute ma veille techno sur la Data, et servant de base √† des articles plus structur√©s.

== Schema-on-Read vs Schema-on-Write

* 2018/09 : https://data-flair.training/forums/topic/what-is-the-difference-between-schema-on-read-and-schema-on-write/

    ** In traditional databases, the table's schema is imposed during the data load time, if the data being loaded does not conform to the schema then the data load is rejected, this process is know as Schema-on-Write. Here the data is being checked against the schema when written into the database(during data load). +
    Now in HIVE, the data schema is not verified during the load time, rather it is verified while processing the query. Hence this process in HIVE called Schema-on-Read. +
    Now, which way is better? Schema-on-Read or Schema-on-Write?

        ** *Schema-on-Read*: +
        Schema-on-Read helps in very fast initial data load, since the data does not have to follow any internal schema(internal database format) to read or parse or serialize, as it is just a copy/move of a file.
        This type of movement of data is more flexible incase of huge data or having two schemas for same underlying data.

        ** *Schema-on-Write*: +
        Schema-on-Write helps in faster performance of the query, as the data is already loaded in a particular format and it is easy to locate the column index or compress the data. However, it takes longer time to load data into the database.

    ** So, in scenarios of large data load or where the schema is not known at load time and there are no indexes to apply, as the query is not formulated, Schema-on-Read(property of HIVE) is more efficient than Schema-on-write.

== Normalisation et d√©normalisation des donn√©es

* https://stph.scenari-community.org/bdd/0/co/optUC004.html

    ** *Normalisation des donn√©es* : processus qui permet d'optimiser un mod√®le logique afin de le *rendre non redondant*. Ce processus conduit √† la fragmentation des donn√©es dans plusieurs tables.
        *** bon site sur la normalisation des donn√©es et les *diff√©rentes formes normales* : https://www.ionos.fr/digitalguide/hebergement/aspects-techniques/normalisation-base-de-donnees/

    ** *D√©normalisation des donn√©es* : Processus consistant √† regrouper plusieurs tables li√©es par des r√©f√©rences, en une seule table, en r√©alisant statiquement les op√©rations de jointure ad√©quates. +
    L'objectif de la d√©normalisation est d'am√©liorer les performances de la BD en recherche sur les tables consid√©r√©es, en impl√©mentant les jointures plut√¥t qu'en les calculant.
        *** *Quand utiliser la d√©normalisation* : Un sch√©ma doit √™tre d√©normalis√© lorsque les performances de certaines recherches sont insuffisantes et que cette insuffisance √† pour cause des jointures.

== 2022/10/21 - Demo de Couchbase Capella

J'ai suivi la d√©mo de Couchbase Capella via leur offre d'essai (trial de 30 jours) de la solution.

Vid√©o explicative : https://www.youtube.com/watch?v=46715VbaHvk

.Comparaison des concepts entre une BDDR et Couchbase
[cols="1,1", options="header"] 
|===
|Relationel model 			|Couchbase
|Server	                    |Cluster
|Database	                |Bucket
|Schema		                |Scope
|Table		                |Collection
|Row		                |Document (JSON or BLOB)
|===

.Exemple
image:20221021_couchbase-capella-demo_01.jpg[]

Why the creation of the index is not done automatically ?

    * Because *manipulating the document using only the ID* is *faster* because using internally the *key / value engine*, which *does NOT require any indexes*.
        ** This works pretty well when you can get the ID of the document

[source,java]
----
// guessing the UserHistory ID using the user's id ('123-hist')
UserHistory hist = userHistoryCollection.get(user.getId() + "-hist")
----

== 2022/05/12 - Le Comptoir OCTO x Dataiku x Snowflake - Comment cr√©er plus de valeur et d√©velopper la collaboration a partir de donn√©es enrichies ?

https://fr.slideshare.net/OCTOTechnology/le-comptoir-octo-x-dataiku-x-snowflake-comment-crer-plus-de-valeur-et-developper-la-collaboration-a-partir-de-donnes-enrichies/OCTOTechnology/le-comptoir-octo-x-dataiku-x-snowflake-comment-crer-plus-de-valeur-et-developper-la-collaboration-a-partir-de-donnes-enrichies

* Pr√©sentation d'une architecture de solution bas√©e sur Snowflake et Data√Øku, avec le soutien d'OCTO Technology

== 2023/01/09 - Rapport tendances 2023 par Didier Girard, section Data

* https://www.linkedin.com/pulse/rapport-tendances-2023-didier-girard : section Data de l'article

* Un des enjeux majeurs de 2023 est de ma√Ætriser le *management* et la *gouvernance de la data*

* R√¥les de la Data : 

    ** *Gouvernance et usage de la donn√©e* : 

        *** *CDO* : +
        Il doit construire une gouvernance de la donn√©e align√©e avec la strat√©gie business de l'entreprise. Ce doit √™tre un manager (ce n'est pas un techos), quelqu'un qui a une vision sur la fa√ßon de mettre la donn√©e au service du business, qui embarquera les √©quipes, les acculturera, qu'il s'agisse des employ√©s ou de ses pairs de la direction.

        *** *Data Domain Owner* : +
        Chaque grand domaine de l'entreprise est responsable de ses donn√©es. Cela devient m√™me flagrant d√®s lors qu'on commence √† raisonner en termes de *Data Mesh*. +
        Les patrons des finances, du marketing, etc. sont donc de facto des Data Domain Owners, un r√¥le qu'ils d√©l√®guent √† des personnes au sein de leurs √©quipes. +
        Ce sont des personnes qui ont une connaissance approfondie de la donn√©e m√©tier, comprennent les enjeux du data-driven, ou comment et pourquoi il faut partager la donn√©e pour la valoriser. +
        Ces personnes doivent d√©crire les jeux de donn√©es au sein des data catalogs, ou encore d√©terminer qui peut y acc√©der et sous quelles conditions (dans le cadre d'un framework de partage d√©termin√© par le CDO).

        *** *Data Stewards* : +
        Les Data Stewards jouent un r√¥le prot√©iforme, puisqu'ils aident les autres acteurs √† d√©finir les normes et processus de collecte, √† s'assurer de la qualit√© des donn√©es, √† r√©soudre certains probl√®mes‚Ä¶ +
        Ce sont eux aussi qui vont assister les utilisateurs de donn√©es pour s'assurer que ces derni√®res sont bien utilis√©es de mani√®re appropri√©e, conform√©ment aux r√®gles de l'entreprise.

    ** *Fabrication et l'exploitation des produits et plateformes Data* : 

        *** *Data architects* : +
        Ils dessinent les grandes lignes de la plateforme, ses principes directeurs et d√©finissent l'articulation entre les composants. Ils poss√®dent des connaissances globales sur l'√©cosyst√®me technique, sont conscients des sp√©cificit√©s techniques et donc des avantages et inconv√©nients des principaux produits, langages et types d'architecture et peuvent aider √† coder si besoin.

        *** *Data engineers* : +
        Ils d√©finissent, d√©veloppent, mettent en place et maintiennent les outils et infrastructures permettant l'analyse de la donn√©e. Sp√©cialis√©s dans les probl√©matiques de croisement et de gestion des donn√©es √† large √©chelle, ce sont eux qui vont impl√©menter les id√©es des Data Analysts.

        *** *Data scientists* : +
        Les Data Scientists construisent des mod√®les math√©matiques de machine learning pour r√©pondre √† des probl√©matiques m√©tier. Dans la majorit√© des cas, ils s'appuieront sur des mod√®les existants qu'ils personnaliseront pour r√©pondre √† des enjeux op√©rationnels. +
        Mais surtout, le r√¥le des Data Scientists ne s'arr√™te plus √† la mise au point des mod√®les ; d√©sormais, ils travaillent conjointement avec les ML Engineers pour s'assurer que leur mod√®le produise des r√©sultats coh√©rents et pertinents tout au long de leur cycle de vie.

        *** *ML engineer* : +
        Ils appliquent les principes du DataOps √† la data science : industrialisation, fiabilit√©, observabilit√©, etc. Ils mettent en place toute l'infrastructure pour que les Data Scientists puissent tester et publier leur mod√®le de fa√ßon automatis√©e, mais aussi obtenir le feedback n√©cessaire pour mettre en ≈ìuvre de l'am√©lioration continue. Ce sont eux qui vont mettre les solutions IA √† l'√©chelle et optimiser la performance globale des mod√®les. De plus en plus, l'aspect IA responsable devrait entrer dans leur champ de pr√©occupations.

        *** *Data Analysts* (et √† terme *TOUS les utilisateurs*) : +
        Les Data Analysts manipulent la donn√©e pour en tirer des enseignements cl√©s, afin de r√©soudre des probl√®mes ou de prendre des d√©cisions mieux inform√©es. S'il s'agit aujourd'hui de r√¥les distincts, il est probable qu'on assiste dans le futur, avec l'acculturation de l'ensemble des collaborateurs √† la donn√©e et la mise √† disposition d'outils self-service "intelligents" (avec de l'IA pour des requ√™tes en langage naturel et des analyses pouss√©es), √† une disparition de ce terme. On √©voquera alors plut√¥t des centaines de millions de personnes analysant de la donn√©e dans le cadre de leur travail quotidien, des graphistes, de propri√©taires de pizz√©rias, de chefs de produits...

* *Data mesh* : 
    ** Data mesh : une architecture particuli√®rement bien adapt√©e aux syst√®mes bas√©s sur les produits
    ** La notion de "mesh", le maillage, *favorise la cr√©ation de produits r√©pondant √† des besoins sp√©cifiques*. Plut√¥t que de vouloir centraliser l'ensemble des donn√©es, l'approche data mesh laisse les responsables de domaines (Domain Data Owners) g√©rer leurs donn√©es, leur qualit√©, qui peut y acc√©der et sous quelles conditions‚Ä¶ +
    Les responsables produits vont cr√©er des produits sur la base de ces donn√©es, et pourront √™tre clients des donn√©es d'autres domaines. Chaque produit peut √©voluer ind√©pendamment en fonction des √©volutions des besoins clients et de l'enrichissement de chaque domaine.
    ** Ce d√©couplage *favorise aussi √† son tour les architectures "event-driven"*, les domaines informant le reste du SI d'√©v√©nements se produisant en leur sein.
    ** Cette *approche f√©d√©r√©e plut√¥t que centralis√©e* donne ainsi plus de latitude - qui ne doit pas √™tre confondue avec de l'anarchie, o√π chacun ferait ce qu'il souhaite dans son coin. C'est pourquoi il est primordial d'instaurer des r√®gles de gouvernance, de mettre en place les r√¥les et responsabilit√©s n√©cessaires, mais aussi une plateforme et un outillage communs qui vont faciliter la cr√©ation et la maintenance de ces produits data.

* *Data management* : une discipline √©troitement li√©e √† l‚Äôinformatique, qui consiste √† mettre en place l‚Äôoutillage n√©cessaire pour g√©rer, s√©curiser et partager les donn√©es.

* *Data governance* : concerne les hommes et l‚Äôusage de la donn√©e : quels sont les r√¥les et responsabilit√©s, quelles sont les r√®gles d‚Äôacc√®s √† la donn√©e, les contraintes l√©gales et √©thiques respecter, pour quels usages‚Ä¶
    ** Un de ses principaux d√©fis : trouver le bon √©quilibre entre l'acc√®s et le contr√¥le des donn√©es.
    ** outils associ√©s : catalogues et dictionnaires de donn√©es, outils de lignage et d'audit des donn√©es, outils de qualit√© et de s√©curit√© des donn√©es.

* *Le partage de la Data* : 
    ** La valorisation de la donn√©e ne sera possible que si les Data Domain Owners jouent le jeu du partage. +
    Contrairement √† l‚Äôor noir, *la donn√©e ne s‚Äô√©puise pas quand on la consomme*, elle cr√©e de nouvelles donn√©es et enrichit √† la fois son producteur et son consommateur.
    ** *Partager la donn√©e* est la condition sine qua non d‚Äôune *strat√©gie data-driven*.

* *DataOps et MLOps remplacent progressivement Datalabs et Data Factories*

    ** La donn√©e en tant que terrain de *jeu* et *d‚Äôexp√©rimentation* touche √† sa *fin*. +
    La crise √©conomique aidant, il s‚Äôagit aujourd‚Äôhui d‚Äô*industrialiser les projets*, de les d√©ployer √† l‚Äô√©chelle et de d√©montrer la capacit√© √† soutenir des processus business et cr√©er de la valeur.
    ** *DataOps* et *MLOps* fournissent le guide d‚Äôutilisation pour mettre en place du CI/CD, de l‚Äôautomatisation et de l'observabilit√©, toutes conditions n√©cessaires √† une *approche industrielle*.

* *FinOps et Data*
    ** Les projets data ne doivent plus d√©marrer sans une composante FinOps, de fa√ßon √† pouvoir attribuer les co√ªts aux diff√©rents domaines m√©tiers.
    ** La d√©marche FinOps s‚Äôassurera aussi que les bonnes pratiques sont respect√©es tout au long du projet, par exemple la *mise en place de seuils et de quotas* qui d√©clencheront des alertes, voire stopperont un service.

* *SQL est le langage universel de la Data*
    ** Tous les syst√®mes qui stockent ou exposent de la donn√©e offrent d√©sormais une prise en charge de SQL
        *** ce qui permet aux utilisateurs d'√©crire des requ√™tes qui combinent des donn√©es provenant de plusieurs sources et d'effectuer des analyses avanc√©es. 
    ** Les avanc√©es r√©centes vont jusqu'√† l'*int√©gration de mod√®les IA et de ML directement dans le langage*.

* *L‚ÄôELT d√©tr√¥ne l‚ÄôETL*
    ** L‚Äôav√®nement des nouvelles architectures de donn√©es privil√©gie le plus souvent le *chargement des donn√©es brutes au sein d‚Äôun datalake*. 
    ** L‚Äô√©tape de transformation est r√©alis√©e ensuite, si elle s‚Äôav√®re n√©cessaire, pour injecter les donn√©es au sein du datawarehouse. +
    De cette fa√ßon, les *data scientists auront acc√®s aux donn√©es brutes* et, si de nouveaux besoins analytiques √©mergent, de nouvelles transformations pourront √™tre op√©r√©es √† partir des donn√©es brutes.
    ** D'o√π un bouleversement du march√© des outils d‚Äôingestion de donn√©es et l'apparition d'*outils se consacrant sp√©cifiquement √† la transformation*, dont le plus populaire est le *framework dbt*

        *** *dbt* : permet de d√©crire les transformations de donn√©es de fa√ßon modulaire, de les tester et de les documenter ; la documentation produite int√©grant automatiquement le lignage de la donn√©e.
        *** La qualit√© du code pouvant laisser √† d√©sirer, le framework *Dataform* (rachet√© puis int√©gr√© √† Google Cloud Platform) a √©t√© cr√©√© avec pour objectif d'y rem√©dier, MAIS est encore tr√®s jeune et doit progresser

IMPORTANT: DANS TOUS LES CAS, *le d√©couplage EL & T para√Æt maintenant act√©*.

* *Data Contracts*
    ** Autre concept pouss√© par l‚Äôessor du data mesh et des architectures distribu√©es

    ** Les Data Contracts sont des *accords entre les producteurs de donn√©es et les consommateurs de donn√©es* qui d√©crivent les attentes et les exigences en mati√®re de qualit√© et de coh√©rence des donn√©es.
        *** Les contrats sont con√ßus pour r√©soudre le probl√®me des changements de sch√©ma inattendus, qui peuvent causer des probl√®mes de qualit√© des donn√©es et perturber les syst√®mes aval.

* *Les bases orient√©es documents alli√©es du "move to cloud"*
    ** *pas de sch√©ma fixe* pour organiser les donn√©es, au lieu de cela stockage dans des documents, √† savoir des collections pouvant avoir diff√©rentes structures et √™tre facilement modifi√©es.
    ** g√®rent un large √©ventail de types de donn√©es, notamment des donn√©es structur√©es, semi-structur√©es et non structur√©es.
    ** tr√®s *performantes* : capables de traiter de grands volumes de donn√©es et des niveaux √©lev√©s de d√©bit
    ** *Hautement disponibles* et peuvent √™tre facilement d√©ploy√©es sur une infrastructure bas√©e sur le cloud

    ** MAIS, PAS adapt√©es √† tous les usages, et n√©cessitent un √©tat d'esprit et des comp√©tences sp√©cifiques diff√©rentes de celles associ√©es aux d√©veloppements "traditionnels"S

* *"No Backend" et services manag√©s*
    ** il s‚Äôagit de se concentrer sur le fonctionnel, et de laisser le management de la base √† un service cloud, qui r√©alisera la maintenance, la sauvegarde, les mont√©es de version, etc.
    ** Le moteur PostgreSQL est ainsi propos√© par de multiples services, chez les fournisseurs de cloud, mais aussi dans l‚Äôopen source, avec Supabase, une solution cr√©√©e comme une alternative √† Firebase (Google) et qui monte dans l‚Äô√©cosyst√®me.
        *** Il s'agit de 2 solutions dites "Backend as a ServiceS"

* *Data Lakehouse, l‚Äôautre nom d‚Äôune Data Platform*
    ** Exemples : Databricks, Starburst, Cloudera, Snowflake

* *De la data analytique √† la data op√©rationnelle*
    ** La capacit√© √† cr√©er des produits avec de la data raffin√©e commence √† sortir du cadre analytique pour revenir dans le cadre op√©rationnel. 
    ** Un cas d‚Äôusage de plus en plus fr√©quent concerne les *r√©f√©rentiels clients uniques*, constitu√©s au sein d‚Äôune data platform √† partir de plusieurs bases clients de diff√©rents syst√®mes op√©rationnels (CRM, ventes, abonnements, SAV, etc.). +
    Les donn√©es r√©concili√©es, nettoy√©es, d√©doublonn√©es, peuvent √™tre r√©inject√©es pour venir servir des syst√®mes op√©rationnels, sous forme de *produits data* mis √† disposition au sein d‚Äôun *hub de donn√©es*, ou inject√©es directement dans une application (op√©ration de type *reverse-ETL*).

== 2023/03/30 : Les 3 grands facteurs cl√©s de succ√®s d'une entreprise data driven

* https://www.wenvision.com/les-facteurs-cles-de-succes-dune-entreprise-data-driven/

* L'organisation data par domaine permet de d√©sengorger la gestion des donn√©es d'une √©quipe centralis√©e et valoriser la connaissance. Elle d√©place la responsabilit√© aupr√®s des domaines ce qui offre en plus d'une expertise technique une expertise m√©tier. La cr√©ation d'√©quipes pluridisciplinaires doit favoriser cette innovation. On parle souvent de *Data Mesh*, pour √©voquer cette d√©centralisation des donn√©es.

== 2023/04/26 : ma r√©action √† l'article de Didier Girard "L'IA g√©n√©rative sera au data catalogue ce que Google a √©t√© √† Yahoo"

L'article de Didier est disponible sur le blog de WEnvision : https://www.wenvision.com/lia-generative-sera-au-data-catalogue-ce-que-google-a-ete-a-yahoo/

Un article tr√®s int√©ressant de Didier, dont je partage pleinement les conclusions, avec beaucoup de curiosit√© sur l'√©volution de ce domaine √† (tr√®s) court terme üòâ 

A l'heure actuelle, la "vraie" "big" data a lieu quand les metadata elles-m√™mes doivent √™tre trait√©es comme de la "big data". +
Depuis quelques temps, nous sommes pass√©s d'une gestion "passive" des metadata (les plateformes de metadata / data catalog √©taient dans l'attente d'une action humaine pour la saisie de metadata et / ou leur cat√©gorisation) √† des "active metadata platforms" comme les appelle le Gartner. +
Ces derni√®res collectent en continu toutes les metadata qu'elles peuvent trouver sur le SI, d'o√π une explosion de la volum√©trie associ√©e.

R√©sultat : il devient tr√®s difficile (voire impossible) de cataloguer cette derni√®re en amont de la cr√©ation / ingestion des metadata. +
Il nous faut donc un moyen de le faire soit au moment de la cr√©ation de la metadonn√©e, soit plus tard, √† la demande, au moment ou on a besoin de se servir des metadata. +
Dans le 1er cas, le probl√®me est de trouver sur quelle base il est possible d'identifier / cat√©goriser cette metadata ? +
Fasse √† des volumes de metadata tr√®s cons√©quents et tr√®s variables, une cat√©gorisation "statique" pr√©d√©finie en amont n'est plus possible ou ad√©quate, il faut donc se baser sur un ensemble de r√®gles dont le but est d'aboutir par calcul √† une cat√©gorisation. +
Souci : ce "calcul de cat√©gorisation" est seulement valable √† un instant "t", car forc√©ment d√©pendant du volume de meta-donn√©e. +
Avec l'av√®nement des "active metadata", la cat√©gorisation d√©termin√©e √† un instant "t" ne sera probablement plus correct √† un instant "t + x" synonyme d'un pourcentage (cons√©quent) de metadata suppl√©mentaires. +
D√®s lors, c'est la 2e solution qui para√Æt la plus pertinente : une cat√©gorisation √† la demande.

Et l√† je rejoins compl√®tement l'avis de Didier, le catalogage "statique" n'est plus possible et doit √™tre remplac√© par un moyen efficace d'aboutir √† cette cat√©gorisation √† la demande : un algorithme rappelant le fonctionnement d'un moteur de recherche. +
C'est √† ce moment qu'on voit l'IA g√©n√©rative entrer en sc√®ne.

Les grandes √©tapes d'√©volution des data catalog ont √©t√© : 

    * Data Catalog 1.0: la gestion des metadata (identification, cat√©gorisation, etc.) est directement l'affaire des √©quipes techniques
    * Data Catalog 2.0: on passe √† une gestion pilot√©e par des √©quipes d√©di√©es (nos data stewards) en lien √©troit avec le m√©tier
    * Data Catalog 3.0: Devant le nombre toujours croissant de metadata, on donne les moyens √† une communaut√© √©tendue d'utilisateurs d'analyser les metadata.

Aujourd'hui, nous arrivons √† l'aube du Data Catalog "4.0" : les metadata deviennent tout simplement trop nombreuses pour un traitement "humain" ou cr√©√© par des humains (les r√®gles changeraient trop vites), nous avons besoin d'une aide, d'une "pr√©-cat√©gorisation" effectu√©e par la machine, c'est l√† que l'IA g√©n√©rative intervient : nous cr√©er / sugg√©rer les cat√©gories les plus pertinentes (entre autres), mais √† la demande. +
Mais est-ce encore un data "catalog" ? Comme le dit Didier, on se trouve davantage face √† un "metadata search engine".

D√®s lors, la question que je me pose est : comment valider cette cat√©gorisation effectu√©e √† la demande, sachant qu'elle est susceptible de changer tr√®s rapidement, avec la prochaine ingestion d'un +x0% de metadata d'un coup (ou plus encore) qui viendra modifier toutes les cat√©gories pr√©c√©demment calcul√©es par l'algo ? +
Une interventation de validation serait impossible ou tr√®s compliqu√©e car tr√®s (trop) limit√©e dans le temps : valider une cat√©gorisation stable sur 1 mois soit, 1 semaine pourquoi pas, mais si cela doit passer √† plusieurs fois par jour ? +
D√®s lors, accepterait-on de croire la cat√©gorisation r√©alis√©e par la machine "sur parole", sans contr√¥le humain ? +
Contrairement √† une "recherche Google classique", qui est avant tout "indicative", les metadata sont √† la base de process op√©rationnels et m√©tier : une information "indicative" n'est pas suffisante, il faut une information "valid√©e". +
Comment valider cette information, son "sens m√©tier" ? +
Pourrait-on imaginer des "Tests Unitaires de cat√©gorisation de donn√©es" ? Mais, ne connaissant ni le r√©sultat √† l'avance (la cat√©gorie !) ni la m√©canique de r√©solution de l'algo, l'√©criture de ces derniers me semble difficile.

J'ai h√¢te de voir comment va √©voluer ce milieu dans les mois √† venir, et √† quoi vont ressembler les prochains data catalog.

== 2023/02/07 - Jordan TIGANI (MotherDuck, l'√©diteur de DuckDB) : Big Data is dead

URL de l'article : https://motherduck.com/blog/big-data-is-dead/

* Jordan utilise / cite le comparateur bien connu "DB Engines" pour comparer les perfs de certaines BDDs.

* Customer data sizes followed a power-law distribution. The largest customer had double the storage of the next largest customer, the next largest customer had half of that, etc. So while there were customers with hundreds of petabytes of data, the sizes trailed off very quickly. There were *many thousands of customers* who paid *less than $10 a month for storage*, which is *half a terabyte*. Among customers who were using the service heavily, the *median data storage size* was much less than *100 GB*.

* He (GCP investissor ?) found that the *largest B2B companies* in his portfolio had around *a terabyte of data*, while the *largest B2C companies* had around *10 Terabytes of data*. +
-> Most, however, had *far less data*.

* *Modern cloud data platforms all separate storage and compute*, which means that customers are not tied to a single form factor. This, more than scale out, is likely the single *most important change in data architectures* in the last 20 years.
    ** *Instead of "shared nothing" architectures* which are hard to manage in real world conditions, *shared disk architectures* let you grow your storage and your compute independently. +
    The rise of scalable and reasonably fast object storage like S3 and GCS meant that you could relax a lot of the constraints on how you built a database.

* *The amount of data processed for analytics workloads is almost certainly smaller than you think*. Dashboards, for example, very often are built from aggregated data. People look at the last hour, or the last day, or the last week's worth of data. Smaller tables tend to be queried more frequently, giant tables more selectively.

* A couple of years ago I did an analysis of BigQuery queries, looking at customers spending more than $1000 / year. *90% of queries processed less than 100 MB of data*.

* A huge percentage of the data that gets processed is less than 24 hours old. By the time data gets to be a week old, it is probably 20 times less likely to be queried than from the most recent day.

* One definition of *"Big Data" is "whatever doesn't fit on a single machine*.. By that definition, the number of workloads that qualify has been decreasing every year.

* An alternate definition of *Big Data is "when the cost of keeping data around is less than the cost of figuring out what to throw away."* 
    ** I like this definition because it encapsulates why people end up with Big Data. It isn't because they need it; they just haven't bothered to delete it. +
    If you think about many data lakes that organizations collect, they fit this bill entirely: giant, messy swamps where no one really knows what they hold or whether it is safe to clean them up.

* Some questions that you can ask to *figure out if you're a "Big Data One-Percenter"*:
    ** Are you really generating a huge amount of data?
    ** If so, do you really need to use a huge amount of data at once?
    ** If so, is the data really too big to fit on one machine?
    ** If so, are you sure you're not just a data hoarder?
    ** If so, are you sure you wouldn't be better off summarizing?

== 2023/01/24 - Ryan BOYD (MotherDuck, l'√©diteur de DuckDB) : How to analyse SQLite databases in DuckDB

* https://motherduck.com/blog/analyze-sqlite-databases-duckdb/

* *DuckDB* is often referred to as the *'SQLite for analytics.'* +
This analogy helps us understand several key properties of DuckDB: 
    ** it's for analytics (OLAP), 
    ** it's embeddable, 
    ** it's lightweight, 
    ** it's self-contained 
    ** and it's widely deployed. +
-> Okay, the latter may not be a given yet for DuckDB, but SQLite says it's likely the most widely used and deployed database engine and, with the rising popularity of analytics, it's quite possible DuckDB will eventually be competitive.

* There are some noticeable differences between SQLite and DuckDB in how data is stored. 
    ** *SQLite*, as a data store *focused on transactions*, *stores data row-by-row* while *DuckDB*, as a *database engine for analytics*, stores *data by columns*. 
    ** Additionally, SQLite doesn't strictly enforce types in the data -- this is known as being weakly typed (or flexibly typed).

== 2023/05/11 - Tech Rocks - Modern Data Stack

Anim√© par : Marie GRAPPE (Choose - Head of Data), Julieu GOULLEY (Fivetran - Senior Solution Architet), Thomas LAPORTE (devoteam - CTO France)

* MDS : Modern Data Stack

image:20230511_tech-rocks_modern-data-stack_01.jpg[]

* Le MDS est une solution Cloud, avec peu de configuration technique et qui ouvre donc la barri√®re d'entr√©e pour plus d'utilisateurs.
* Les caract√©ristiques cl√©s de la MDS : 
    ** Cloud-First
    ** ETL remplac√© par une approche ELT
    ** SQL-based
    ** Enti√®rement manag√©
        *** l'automatisation de l'acc√®s aux donn√©es est un des piliers de la MDS. Vous n'avez plus √† cr√©er et manager des pipelines vous-m√™mes.

* Thomas LAPORTE : Plut√¥t qu'une "stack", la MDS est davantage une collection d'outils

* Julien Goulley : "DBT qui est un outil de transformation qui permet d'√©crire des mod√®les en SQL [...]"

Et maintenant un autre article, 2022/07, *critique de la MDS* : https://anaselk.com/p/modern-data-stack-dead/

    * Il en ressort ce sch√©ma, o√π une approche plus raisonnable que la MDS est propos√©e (appel√©e "Postmodern Data Stack" par l'auteur, Lauren Balik) : +
    image:202207_modern-data-stack-vs-more-reasonable-stack.jpg[]

Pour un autre *recensement des technologies derri√®re la Modern Data Stack*, voir ce site : https://notion.castordoc.com/modern-data-stack-guide +
image:20230511_tech-rocks_modern-data-stack_02.jpg[]

== 2023/05/12 - Starburst Academy : The difference between data lakes and data lakehouses

* URL : https://www.youtube.com/watch?v=k1cch-6bZhM

* *Modern data formats* replaced traditional old Hive format. +
Those new modern data formats : 
    ** Apache *Iceberg*
    ** Databricks *Delta Lake*
    ** Apache *Hudi*

* Hive tables lack ACID compliance and version control -> not the case of those modern data formats

* *Those new data formats are what make a lakehouse a lakehouse*.
    ** With Hive, we create a data lake
    ** with those formats, we create a data lakehouse

* Compared to data lake, those new formats handle better performance, data modification and schema evolution
    ** Ces nouveaux formats permettent des performances proches des data warehouse ou des BDDs, tout en utilisant un stockage objet, comme les data lakes.

* Data lakehouse improves the *reporting structure*.
    ** data lakes store metadata limited to : location, format, structure BUT they do NOT record a comprehensive end to end record of all changes made to a table.
    
    ** On the other side, data *lakehouses* store *large amounts of metadata* painting a *comprehensive picture of the system*, including record by record details of : 
        *** every modifications
        *** every updates
        *** every deletions
    ** Those metadata are stored in a set of hierarchically structured files : *manifest files*
        *** Manifest files capture changes in the state of the dataset, providing the ability to record an accurate up-to-date account of the changes occurring in the table at any given time : inserts, deletions, updates, schema migrations, partition updates +
        image:20230512_starburst-academy_data-lakehouse-modern-data-formats_01.jpg[]

* How Iceberg uses metadata manifest files to create a transactional layer on top of traditional data lake storage : 
    ** if a change is made TO THE DATA (let's a file persistance in this example) -> a manifest file is created that references a specific section of the data
    ** multiple manifest files are referenced in a manifest list
    ** manifest list is contained in a metadata file
    ** this metadata file is held in the Iceberd catalog

    ** The metadata held in the lakehouse ~ a database transaction log that sits on top of the traditional cloud object storage (this last making up a data lake)

* Collectively *those manifest files create a kind of snapshot*
    ** Iceberg calls them just that : *Snapshot files*
    ** Delta lake uses the Delta log in a similar way

    ** These snapshots detailed the points at which the changes are made
        *** So they can be used to query the database at a particular point in time, facilitate schema and partition evolution, or roll back changes

* Those numerous metadata and their possibilities are what make the differences between data lake and data lakehouse : 
    ** record level updates
    ** ACID compliance
    ** transaction support
    ** data concurrency support

image:20230512_starburst-academy_data-lakehouse-modern-data-formats_02.jpg[]

== 2023/06/20 - DZone - The Great Data Mesh Debate: Will It Sink or Swim?

Tr√®s bon article sur le *Data Mesh* üëç +
https://dzone.com/articles/the-great-data-mesh-debate-will-it-sink-or-swim

* L'inspiration du Data Mesh : 

    ** Akin to how software engineering teams transitioned from monolithic applications to microservice architectures, *the data mesh represents the data platform equivalent of microservices*. +
    Drawing *inspiration from Eric Evans' domain-driven design theory*, which advocates for flexible and scalable software development aligning with specific business domains, the data mesh offers a comparable approach.

* D√©finition du Data Mesh :

    ** Coined by *Zhamak Dehghani*, the former principal consultant at ThoughtWorks, in 2019, *data mesh* presents a novel approach to *managing analytical data through a distributed architecture*. 
    ** By enabling end-users to *directly access and query data in its original location*, data mesh *eliminates the need for centralization in data lakes or warehouses*. Under this paradigm, *data is treated as a product*, with *ownership vested in the teams* most closely involved in its consumption and understanding.

* Foundations of Data Mesh : 

    ** managing data by domain
    ** treating data as a product
    ** enabling self-service data platforms
    ** implementing federated computational governance

.Gartner Hype Cycle for Data Management, 2022
[NOTE]
====
Cet article s'appuie l'analyse du Data Mesh r√©alis√©e dans l'√©tude Hype Cycle du Gartner pour le Data Management, paru le 2022/06/30. +
-> Voir la section √† suivre pour la partie de l'√©tude du Gartner associ√©e au Data Mesh.

.Gartner Hype Cycle for Data Management, 2022
image:20220630_Gartner_Hype-Cycle-for-Data-Management.png[]
====

.Gartner : l'approche Data Mesh sera obsol√®te avant le plateau de productivit√©
[IMPORTANT]
====
Gartner analysts Mark Beyer, Ehtisham Zaidi, and Robert Thanaraj quantified the perceived *benefits of data mesh as low* and noted that its market penetration among the target audience is also relatively low, ranging between 1 to 5 percent. The hype surrounding data mesh arises from claims that it addresses challenges in centralized data warehouses, data lakes, and data hubs.
====

* However, with the advancement of technologies and solutions supporting centralized data access, *distributed approaches like data mesh are anticipated to lose popularity* within enterprise IT.
* Malcolm Hawker, former Gartner analyst and current head of data strategy at Profisee, defended Gartner's observation. He clarified that Gartner does not believe data mesh is currently obsolete, but rather, the chart indicates future obsolescence. Hawker expressed Gartner's belief that the *data fabric will emerge as the dominant data management architectural pattern*, eventually rendering data mesh obsolete.

* *Data Mesh* is one of many *attempts at decentralizing data management*. Previous experiences, such as the transition from centralized data warehousing to domain-focused approaches, have faced challenges.

== 2022/06/30 - Gartner Hype Cycle for Data Management, 2022 - Data Mesh

URL du rapport complet : https://www.gartner.com/doc/reprints?id=1-2B6AXOGW&ct=220920&st=sb

IMPORTANT: Le Gartner a conclu que l'approche *Data Mesh* serait [red]*obsol√®te avant le plateau de productivit√©*.

*Data Mesh* + 
*Analysis By* : Mark Beyer, Ehtisham Zaidi, Robert Thanaraj +
*Benefit Rating* : Low +
*Market Penetration* : 1% to 5% of target audience +
*Maturity* : Embryonic

*Definition* : +
Data mesh is an access approach based on *data domains* and *distributed data management*. Operational data assets are analyzed for usage patterns and their affinity to each other ‚Äî defining domains. Domains are combined with business context descriptors to create *data products*. Data products are registered and made available for *reuse relative to business needs*, and are used throughout the organization. *Data governance authority is distributed to business applications*.

*Why This Is Important* : +
Data mesh represents a potential *alternative* or complement *to centralization-only data management strategies* for analytics and other reuse cases after first data capture in primary enterprise systems. Organizations continuously seek for a means to balance data requirements for repeatability, reusability, governance, authority, provenance and optimized delivery.

IMPORTANT: Data mesh *shifts responsibility* for data governance back to enterprise application designers and users.

*Business Impact* : +
From a governance and authoritative perspective, data mesh relies upon the business and data domain expertise of subject matter experts (SMEs). SMEs are assumed to exhibit the greatest experience in capturing and using data within their domain of expertise. They are responsible for determining guidance and processes for creating, managing and preventing unnecessary proliferation of the data products.

IMPORTANT: The goal of the mesh is to *provide ready access to data from as close to the source as possible*.

*Drivers* :

    * Mesh asserts it has the potential to decrease time and effort required to enable data reuse throughout an enterprise when it leverages existing assets instead of centralizing the data architecture.
    * Data mesh hype is due to assertions it remediates difficulties in approaches like centralized data warehouses, data lakes and data hubs.
    * Data mesh renews a recurring argument that business applications are the most capable of capturing data and therefore render the most authoritative data.
    * *Delays in data access and utilization* are the *most frequently reported issues* from organizations that are seeking to deploy data for ongoing use cases. The successes of data centralization solutions have all been questioned.
    * Data mesh emerges as a response to delivery compromises, negotiation, budgets and miscomprehension that are the primary causes for failed, centralized data management implementations. Failures in these areas are primarily the result of poor delivery and implementation. Implementers focusing on technical delivery and perceived failures stem from adjacent data management methodologies that are easily alienated from the broader business domain requirements. The alienation stretches delivery time, increases maintenance requirements and challenges data validity. The current abundance of resources does not alleviate the inevitable resurgence of resource constraints that will take place when fast and agile business application development creates a rapid expansion of data availability in even more disparate forms.
    * *Data mesh proposes that it is not necessary to duplicate data from multiple source systems*. However, application designs assert degrees of autonomy relative to internal data capture ‚Äî in some cases this is justified, and in others is overreach. Operational applications are intentionally designed to specifically omit data when it is NOT relevant to supporting the intended business process, leaving data gaps.

*Obstacles* :

    * Data management maturity is required for: data governance at the business domain level, though coordinated with enterprise governance (if it exists); data completeness from sources; application design and deployment; data quality; data provenance; systems architecture; analytics data management.
    * Data products must be properly designed by subject matter experts (SMEs) as reusable data products that describe business functions and tasks.
    * *Data products must be able to meet the service level objectives for other groups sharing the data*.
    * *System design skills* to ensure service levels *may not be present* in the business units.
    * "Design by committee" experiences or lead designer *arrogance* have inherent risk. SME expertise across multiple use cases for data domains is often multiple individuals.
    * Inappropriate identification of either data detail or correct integrity for combining them will result in data product proliferation, leading to increased management and maintenance, and eventual collapse of the mesh.

*User Recommendations* : 

    * Assess data products for business domain alignment and demonstrable reduction of level of effort upon delivery. Control data product proliferation by assuring they can be *deconstructed* and *reconstructed*.
    * Proceed with the assumption that multiple systems may have authority over different attributes within a data domain. Differing detail levels from sources will require resolution. Individual systems will have gaps in the data needed for a data product.
    * Data product design must address management and governance contention issues within data domains in order to mitigate irresponsible data management emanating from sources.
    * Leverage colocated data solutions that solve performance and efficiency issues (lakes, warehouses, or hubs).
    * Leverage existing quality, integration, virtualization or other data management technologies as inputs to the mesh.
    * Utilize point solution providers to build a data mesh gradually.

*Sample Vendors* : +
Cinchy; Denodo; Informatica; K2View; Starburst.IO; TIBCO; Zetaris

== 2023/09/29 - Pr√©paration √©tat des lieux technologiques

=== La fin du Data Mesh ?

* DATA MESH : De mani√®re g√©n√©rale, les *data mesh* sont des *architectures de donn√©es distribu√©es*, dans lesquelles *les donn√©es sont d√©centralis√©es* et *g√©r√©es par les √©quipes m√©tier* qui en ont besoin. 
	** l'approche Data Mesh implique l'usage de *solutions de Data integration* comme Cinchy, Denodo, Informatica, K2View, Starburst.IO, TIBCO : permettent aux entreprises de connecter leurs diff√©rentes sources de donn√©es et de les mettre √† disposition des utilisateurs. Ces solutions sont donc essentielles pour la mise en place d'un data mesh, car elles permettent aux √©quipes m√©tier de r√©cup√©rer les donn√©es dont elles ont besoin, l√† o√π elles se trouvent.
	** et de *Data Gouvernance* comme Zetaris : permet de garantir que les donn√©es sont de qualit√© et qu'elles sont utilis√©es de mani√®re responsable.

* DATA FABRIC : Les data fabric, quant √† eux, sont des *architectures de donn√©es centralis√©es*, dans lesquelles les donn√©es sont stock√©es et g√©r√©es dans une plateforme unique.

	** Donc davantage le *concept de data lake, ou data lakehouse*.
		*** "Avant" on aurait tout de suite pens√© aux Cloud data lakehouse comme Snowflake, Databricks, Big Query (mais PAS Synapses comme vu pr√©c√©demment), mais maintenant une nouvelle voix semble √©galement √™tre possible, le retour du on-premise avec des solutions comme DuckDB qui rendent possible de traiter avec du SQL des volumes de donn√©es importants r√©sidant dans du stockage objets. 
			**** Et en plus on peut le faire en conservant le contr√¥le de la souverainet√© de nos donn√©es sans prendre de risque avec le RGPD.
		*** Voir la conf de Vincent HEUSCHLING au Voxxed Days Luxembourg de 2023/07 "Pourquoi DuckDB pourrait √™tre le moteur de votre Datalake ?" : https://www.youtube.com/watch?v=HNGm9rE3FCk

* Concernant le Data Mesh, les objectifs, louables √©taient les suivants :

	** Data mesh represents a potential *alternative* or complement *to centralization-only data management strategies* for analytics and other reuse cases after first data capture in primary enterprise systems. Organizations continuously seek for a means to balance data requirements for repeatability, reusability, governance, authority, provenance and optimized delivery.
	** Data mesh *shifts responsibility* for data governance back to enterprise application designers and users.
	** L'approche Data Mesh a donc √©t√© pouss√©e comme √©tant une solution aux probl√®mes inh√©rents aux solutions de centralisation de donn√©es de type data warehouse, data lake et data lakehouse.

* MAIS ces objectifs se heurtent √† de s√©rieux obstables : 

	** *Data management maturity* is required for: data governance at the business domain level, though coordinated with enterprise governance (if it exists); data completeness from sources; application design and deployment; data quality; data provenance; systems architecture; analytics data management.
    ** Data products must be properly designed by subject matter experts (SMEs) as *reusable data products* that describe business functions and tasks.
    ** *Data products must be able to meet the service level objectives for other groups sharing the data*.
    ** *System design skills* to ensure service levels *may not be present* in the business units.
    ** "Design by committee" experiences or lead designer *arrogance* have inherent risk. SME expertise across multiple use cases for data domains is often multiple individuals.
    ** Inappropriate identification of either data detail or correct integrity for combining them will result in data product proliferation, leading to increased management and maintenance, and eventual collapse of the mesh.

	** En gros, on revient aux "bons vieux probl√®mes bien connus" des donn√©es silot√©es √† droite √† gauche : on peut les g√©rer avec une TRES BONNE organisation, mais dans la pratique, tr√®s rares sont les entreprises qui r√©ussissent ce tour de force. +
	Et ce n'est pas l'ajout d'outils qui va changer ce constat.

Partant de ce constat, les voix doutant de la pertinence de l'approche Data Mesh se font de plus en plus nombreuses. +
Parmi celles-ci on peut citer le Gartner qui a statu√© (Gartner Hype Cycle for Data Management, 2022, utiliser l'image dans misc-data-notes.adoc) en 2022 que le Data Mesh serait obsol√®te avant le plateau de productivit√©

* Autre article r√©cent en faveur du Data mesh cette fois : https://dzone.com/articles/evolving-data-strategy-at-a-major-canadian-bank
	** on y trouve un bon sch√©ma de l'ingestion des data, sous forme de data assets, dans le Cloud, puis de leur transformation en data products au sein de ce dernier.
* Je trouve ce paragraphe tr√®s int√©ressant : +
"The CIBC data strategy is not a technological shift. It's a transformational shift. When we are thinking about data migration to the cloud, it's not about moving data from one technology to another. It's *not just a lift-and-shift* of the data to the cloud. The *data must be ingested into the right data products* to avoid data duplication and assure data quality. A *data product* representing a certain business area *becomes a single source of these data* to consumers for reporting, analytics, and AI/ML. For example, just one and only one data product will provide customer data to the rest of the organization."
	** Et c'est un peu tout le probl√®me √† mes yeux : les grosses difficult√©s de l'approche Data Mesh sont avant tout organisationnelle √† mes yeux. +
	Comment d√©finir le "bon" data product, et se mettre tous d'accord pour que seul un soit d√©fini pour un concept donn√© (customer data dans l'exemple) et devienne la source de v√©rit√© pour ce dernier ? (beaucoup de politique √† ce niveau)
* Idem avec cette phrase : "If we are not moving data to *the right data products*, we can't say we are moving data to the data mesh." +
-> Bien d'accord, c'est toute la difficult√©. *Cr√©er le bon data product est le point central, et le principal challenge du data mesh*.
	** L'article lui-m√™me met bien en avant la difficult√© de la chose : "Keep in mind that it's not black-and-white. It could be a complex iterative process, a kind of mix of art and science. The approach might need to be adjusted depending on use cases and data types."

	** On voit bien dans la description de mise en place de l'approche Data Mesh propos√©e par l'article qu'elle est d'une telle complexit√© qu'il va √™tre quasi-obligatoire pour la grande majorit√© des entreprises d'avoir recours √† une soci√©t√© de conseil sp√©cialis√©e.
		
C√¥t√© Softeam, 2 aspects sont √† prendre en compte : 

	* Nos clients vont demander l'approche Data mesh, √† nous de former nos consultants pour r√©pondre √† leurs besoins
	* MAIS, il faudra √©galement former ces m√™mes consultants aux risques du data mesh et √† ses alternatives (lakehouse, data fabric) afin que ces derniers puissent proposer d'autres solutions s'ils constatent en mission un "fail" du data mesh. +
	-> Notre valeur ajout√© sera √©galement l√†.

=== Les nouveaux formats de la Data (Iceberg, Delta Lake, Hudi)

* Those new modern data formats : 
    ** Apache *Iceberg*
		*** Apache Iceberg, the open source high-performance format for huge analytic tables
		*** https://www.dremio.com/blog/a-hands-on-look-at-the-structure-of-an-apache-iceberg-table/[]
		*** "Apache Iceberg is a high-performance, open table format for large-scale analytics. It has rapidly gained momentum as the standard for table formats in a data lake architecture. Iceberg brings capabilities such as ACID compliance, full schema evolution (using SQL), partition evolution, time travel, etc., that address some of the key problems within data lakes and enable warehouse-level functionalities. What allows Iceberg to facilitate these capabilities and achieve high performance is the way it is designed. The diagram below illustrates the high-level components that form the Iceberg architecture." +
		image:20230929_etat-des-lieux-tech_apache-iceberg-table-structure.jpg[]
    ** Databricks *Delta Lake*
		** https://docs.databricks.com/en/delta/index.html#:~:text=Delta%20Lake%20is%20open%20source,transactions%20and%20scalable%20metadata%20handling.[]
		** "Delta Lake is the optimized storage layer that provides the foundation for storing data and tables in the Databricks Lakehouse Platform. +
		Delta Lake is open source software that extends Parquet data files with a file-based transaction log for ACID transactions and scalable metadata handling."
    ** Apache *Hudi*

* *Those new open source data formats are what make a lakehouse a lakehouse*.
    ** With Hive, we create a data lake
    ** with those formats, we create a data lakehouse

* Hive tables lack ACID compliance and version control -> not the case of those modern data formats

* Compared to data lake, those new formats handle better performance, data modification and schema evolution
    ** Ces nouveaux formats permettent des *performances proches des data warehouse ou des BDDs*, *tout en utilisant un stockage objet*, comme les data lakes.

* Tous les √©diteurs de solutions analytiques (cloud data lakehouse) √©tudient et maintenant poussent l'adoption de ces formats : Snowflake, Databricks, BigQuery, etc.

* 2022/07/13 : aujourd'hui un Big Query est capable de lire des fichiers parquet dans du storage, et l√† snowflake est capable de lire des Apache *Iceberg* tables √† l'ext√©rieur. Cela va permettre d'unifier l'acc√®s aux donn√©es au sein de snowflake sans avoir besoin d'un outil tierce (comme un Trino).
	** Pour rappel, *Starburst* est une "data lake analytics platform" construite sur *Trino* (anciennement PrestoSQL)
		*** Et Trino est un moteur d'analyse distribu√©, open source et SQL, qui permet d'interroger des donn√©es provenant de diff√©rentes sources, qu'elles soient structur√©es, non structur√©es ou semi-structur√©es.

* Info en passant, la guerre Snowflake vs Databricks continue de faire rage : 
	** Snowflake est maintenant en train de chercher √† concurrencer Databricks sur toute la partie "d√©veloppeur"
	** Et Databricks cherche √† concurrencer Snowflake sur la BI...
		*** La force de Databricks reste la partie ML avec Spark, l√† o√π Snowflake reste un outil de BI SQL

* Snowflake est tr√®s bon dans son format propri√©taire, mais vraiment mauvais pour traiter des fichiers Iceberg dans s3 (for querying data outside of their own database)
	** -> S'ils le font c'est qu'ils ont la pression de concurrents comme Starburst et Databricks qui le font d√©j√†.

* *Pourquoi utiliser ces formats ?*

	** Force d'un format open source comme Iceberg compar√© √† un format propri√©taire comme le format de Snowflake.
	** A des fins de portabilit√© : tout le monde souhaite "a single source of truth for data", une *source unique de v√©rit√©* pour la Data

.La nouvelle "vraie" Big Data
NOTE: Plus de 100 To g√©n√©ralement, et c'est quand les metadata deviennent de la Big Data...





